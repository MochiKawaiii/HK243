{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Học Tăng Cường - Reinforcement Learning\n",
    "## Thực hành 20 đến Thực hành 24\n",
    "Nội dung bao gồm:\n",
    "- Tìm đường mê cung bằng DFS và BFS (6x6)\n",
    "- FSSP_BFS trên lưới và đồ thị\n",
    "- Q-Learning đơn giản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đường đi tìm bằng DFS: [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (2, 1), (2, 2), (1, 2), (0, 2), (0, 3), (1, 3), (2, 3), (2, 4), (1, 4), (1, 5), (0, 5)]\n"
     ]
    }
   ],
   "source": [
    "# TH20: DFS - Tìm đường trong mê cung 6x6\n",
    "maze_size = 6\n",
    "obstacles = {(0,1), (1,1), (3,2), (3,3), (3,4), (3,5), (0,4), (4,1), (4,2), (4,3)}\n",
    "maze = [[0]*maze_size for _ in range(maze_size)]\n",
    "for (r,c) in obstacles:\n",
    "    maze[r][c] = 1\n",
    "start = (0,0)\n",
    "goal = (0,5)\n",
    "\n",
    "def is_valid(cell):\n",
    "    r, c = cell\n",
    "    return 0 <= r < maze_size and 0 <= c < maze_size and maze[r][c] == 0\n",
    "\n",
    "visited = set()\n",
    "path = []\n",
    "def dfs(cell):\n",
    "    if cell == goal:\n",
    "        path.append(cell)\n",
    "        return True\n",
    "    visited.add(cell)\n",
    "    r, c = cell\n",
    "    for m in [(r-1,c), (r+1,c), (r,c-1), (r,c+1)]:\n",
    "        if is_valid(m) and m not in visited:\n",
    "            if dfs(m):\n",
    "                path.append(cell)\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "if dfs(start):\n",
    "    path.reverse()\n",
    "    print(\"Đường đi tìm bằng DFS:\", path)\n",
    "else:\n",
    "    print(\"Không tìm thấy đường đi bằng DFS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFS (Depth-First Search) là thuật toán tìm kiếm theo chiều sâu, thường được sử dụng để tìm đường đi trong mê cung hoặc đồ thị bằng cách khám phá “càng sâu càng tốt” trên mỗi nhánh trước khi quay lui\n",
    ". Trong đoạn mã trên, chúng ta định nghĩa một mê cung 6x6 với các chướng ngại vật và khởi tạo vị trí bắt đầu start và đích goal. Hàm dfs thực hiện tìm kiếm theo chiều sâu đệ quy: khi cell hiện tại là đích, trả về True và thêm ô đó vào đường đi; nếu không, tiếp tục duyệt các bước di chuyển hợp lệ (lên, xuống, trái, phải). Biến visited theo dõi các ô đã duyệt để tránh lặp vô tận. Cuối cùng, nếu tìm được đường đi từ start đến goal, đường đi được thu được qua biến path (đã được đảo ngược đúng thứ tự) và in ra màn hình.\n",
    "Mô tả chi tiết: Đầu tiên, ta tạo mê cung dưới dạng ma trận 6x6 và đánh dấu chướng ngại vật. Hàm is_valid(cell) kiểm tra ô có nằm trong tầm hoạt động và không bị chặn. Hàm dfs(cell) duyệt đệ quy: nếu gặp đích thì kết thúc thành công, ngược lại đánh dấu ô hiện tại đã thăm và thử từng ô láng giềng hợp lệ chưa thăm. Nếu bất kỳ đường nào dẫn đến đích, nó thêm cell vào đường đi. Cuối cùng gọi dfs(start) và in ra đường tìm được hoặc thông báo không tìm thấy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đường đi tìm bằng BFS: [(0, 0), (1, 0), (2, 0), (2, 1), (2, 2), (1, 2), (1, 3), (1, 4), (1, 5), (0, 5)]\n"
     ]
    }
   ],
   "source": [
    "# TH21: BFS - Tìm đường trong mê cung 6x6\n",
    "from collections import deque\n",
    "\n",
    "def bfs(start, goal):\n",
    "    queue = deque([(start, [start])])\n",
    "    visited = set([start])\n",
    "    while queue:\n",
    "        (cell, path) = queue.popleft()\n",
    "        if cell == goal:\n",
    "            return path\n",
    "        r, c = cell\n",
    "        for m in [(r-1,c), (r+1,c), (r,c-1), (r,c+1)]:\n",
    "            if is_valid(m) and m not in visited:\n",
    "                visited.add(m)\n",
    "                queue.append((m, path + [m]))\n",
    "    return None\n",
    "\n",
    "bfs_path = bfs(start, goal)\n",
    "if bfs_path:\n",
    "    print(\"Đường đi tìm bằng BFS:\", bfs_path)\n",
    "else:\n",
    "    print(\"Không tìm thấy đường đi bằng BFS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BFS (Breadth-First Search) là thuật toán tìm kiếm theo chiều rộng, khám phá các ô (hoặc nút) “tầng tầng lớp lớp” từ vị trí nguồn, bảo đảm thăm hết tất cả các ô ở mức độ hiện tại trước khi đến mức tiếp theo\n",
    ". Điều này có nghĩa là BFS thường tìm được đường đi ngắn nhất trong mê cung không trọng số. Trong đoạn mã trên, ta sử dụng deque làm hàng đợi để lần lượt duyệt các vị trí. Đầu tiên thêm start vào hàng đợi. Mỗi lần lặp, ta lấy vị trí hiện tại và đường đi đã đi đến đó; nếu vị trí là goal, trả về đường đi. Ngược lại, thử các bước di chuyển (lên, xuống, trái, phải) mà chưa thăm, đánh dấu là đã thăm và thêm vào hàng đợi cùng với đường đi tương ứng. Kết quả là bfs_path lưu đường ngắn nhất từ start đến goal, và được in ra.\n",
    "Mô tả chi tiết: Thuật toán BFS sử dụng cấu trúc hàng đợi để đảm bảo thăm các ô theo khoảng cách gia tăng từ start\n",
    ". Biến visited lưu các ô đã thăm để tránh lặp. Tại mỗi bước, ta kiểm tra nếu đã tới đích, ngược lại thêm tất cả ô láng giềng hợp lệ vào cuối hàng đợi cùng với đường đi tới ô đó. Do đặc tính tìm kiếm theo mức độ, kết quả cuối cùng là đường đi ngắn nhất từ đầu đến đích được tìm thấy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đường đi tìm bằng BFS trên lưới: [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)]\n"
     ]
    }
   ],
   "source": [
    "# TH22: BFS trên lưới 5x5 - FSSP\n",
    "grid = [[0]*5 for _ in range(5)]\n",
    "grid[1][1] = 1\n",
    "grid[2][3] = 1\n",
    "start = (0,0)\n",
    "goal = (4,4)\n",
    "\n",
    "def is_valid_grid(cell):\n",
    "    r, c = cell\n",
    "    return 0 <= r < 5 and 0 <= c < 5 and grid[r][c] == 0\n",
    "\n",
    "def bfs_grid(start, goal):\n",
    "    queue = deque([(start, [start])])\n",
    "    visited = set([start])\n",
    "    while queue:\n",
    "        cell, path = queue.popleft()\n",
    "        if cell == goal:\n",
    "            return path\n",
    "        r, c = cell\n",
    "        for m in [(r-1,c), (r+1,c), (r,c-1), (r,c+1)]:\n",
    "            if is_valid_grid(m) and m not in visited:\n",
    "                visited.add(m)\n",
    "                queue.append((m, path + [m]))\n",
    "    return None\n",
    "\n",
    "fssp_path = bfs_grid(start, goal)\n",
    "print(\"Đường đi tìm bằng BFS trên lưới:\", fssp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FSSP (Forward State Space Planning) là kỹ thuật lập kế hoạch tiến về phía trước, ứng dụng thuật toán tìm kiếm như BFS để khám phá dần các trạng thái của hệ thống từ start tới goal\n",
    ". Ở đây ta coi mỗi ô trong lưới là một trạng thái. BFS sẽ tìm đường đi ngắn nhất trên lưới bằng cách lần lượt khám phá các ô theo khoảng cách tăng dần từ ban đầu. Đoạn mã trên định nghĩa một lưới 5x5 với vài ô chắn, sử dụng hàm bfs_grid tương tự như BFS thông thường. Ở mỗi bước, nếu vị trí hiện tại là đích, trả về đường đi; nếu không, thêm các ô láng giềng hợp lệ vào hàng đợi và tiếp tục. Kết quả fssp_path là đường tìm được.\n",
    "Mô tả chi tiết: Chúng ta biểu diễn lưới dưới dạng ma trận và dùng BFS để lần lượt thăm các ô như trong thuật toán FSSP\n",
    ". Hàm is_valid_grid(cell) kiểm tra ô có trong lưới và không bị chặn. Tương tự BFS thông thường, ta dùng hàng đợi lưu cặp (ô hiện tại, đường đi). Duyệt cho đến khi tới goal. Vì BFS trên lưới không trọng số đảm bảo đường đi tìm được là ngắn nhất, đây là cách tìm đường nhanh chóng trong mô hình trạng thái tiến của bài toán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đường đi trong đồ thị: ['A', 'C', 'F']\n"
     ]
    }
   ],
   "source": [
    "# TH23: BFS trên đồ thị\n",
    "graph = {\n",
    "    'A': ['B','C'],\n",
    "    'B': ['D','E'],\n",
    "    'C': ['F'],\n",
    "    'D': [],\n",
    "    'E': ['F'],\n",
    "    'F': []\n",
    "}\n",
    "\n",
    "def bfs_graph(graph, start, goal):\n",
    "    queue = deque([(start, [start])])\n",
    "    visited = set([start])\n",
    "    while queue:\n",
    "        node, path = queue.popleft()\n",
    "        if node == goal:\n",
    "            return path\n",
    "        for neighbor in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append((neighbor, path + [neighbor]))\n",
    "    return None\n",
    "\n",
    "graph_path = bfs_graph(graph, 'A', 'F')\n",
    "print(\"Đường đi trong đồ thị:\", graph_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BFS cũng có thể áp dụng cho tìm đường trên đồ thị (mạng lưới đặc biệt) với cách tiếp cận tương tự. Thuật toán sẽ thăm lần lượt các đỉnh kề nhau và đảm bảo tìm được đường ngắn nhất từ đỉnh bắt đầu đến đỉnh đích trong đồ thị không trọng số\n",
    ". Đoạn mã định nghĩa một đồ thị dưới dạng danh sách kề (các khóa là nút, giá trị là danh sách nút kề). Hàm bfs_graph thực hiện BFS: mỗi lần lấy một nút, nếu đó là đích thì trả về đường đi; nếu không, thêm các nút kề chưa thăm vào hàng đợi cùng đường đi dẫn tới chúng. Kết quả graph_path là đường từ ‘A’ tới ‘F’, đảm bảo ngắn nhất.\n",
    "Mô tả chi tiết: Giống như BFS trên lưới, BFS trên đồ thị sử dụng hàng đợi để thăm từng lớp đỉnh một\n",
    ". Mỗi lần ta xử lý một cặp (đỉnh, đường đi) từ hàng đợi. Nếu đỉnh là goal, giải quyết dừng lại. Ngược lại, các đỉnh kề chưa thăm sẽ được thêm vào hàng đợi. Biến visited ngăn trùng lặp. Nhờ tính chất BFS, đường đi tìm được luôn có số bước nhỏ nhất. Đoạn mã sau cùng in ra đường đi tìm được trong đồ thị này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bảng Q sau huấn luyện:\n",
      "[[0.59048994 0.6561    ]\n",
      " [0.59048999 0.729     ]\n",
      " [0.65609996 0.81      ]\n",
      " [0.729      0.9       ]\n",
      " [0.81       1.        ]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# TH24: Q-Learning đơn giản\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "n_states = 6\n",
    "goal_state = n_states - 1\n",
    "n_actions = 2  # 0: trái, 1: phải\n",
    "\n",
    "def next_state(state, action):\n",
    "    if action == 0:\n",
    "        return 0 if state == 0 else state - 1\n",
    "    else:\n",
    "        return goal_state if state == goal_state else state + 1\n",
    "\n",
    "def reward(state, action, new_state):\n",
    "    return 1 if new_state == goal_state else 0\n",
    "\n",
    "Q = np.zeros((n_states, n_actions))\n",
    "alpha = 0.8\n",
    "gamma = 0.9\n",
    "epsilon = 0.1\n",
    "episodes = 500\n",
    "\n",
    "for ep in range(episodes):\n",
    "    state = random.randint(0, n_states - 1)\n",
    "    while state != goal_state:\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randint(0, n_actions - 1)\n",
    "        else:\n",
    "            action = int(np.argmax(Q[state]))\n",
    "        new_state = next_state(state, action)\n",
    "        r = reward(state, action, new_state)\n",
    "        Q[state, action] += alpha * (r + gamma * np.max(Q[new_state]) - Q[state, action])\n",
    "        state = new_state\n",
    "\n",
    "print(\"Bảng Q sau huấn luyện:\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong Q-learning, tác nhân duy trì một bảng Q-table lưu giá trị kỳ vọng của mỗi cặp (trạng thái, hành động). Mỗi lần thực hiện hành động, tác nhân nhận phần thưởng và cập nhật giá trị Q theo công thức Q(S,A) ← Q(S,A) + α (R + γ max_a Q(S',a) - Q(S,A))\n",
    ". Ở đoạn mã trên, ta thiết kế môi trường tuyến tính gồm 6 trạng thái (trạng thái 5 là đích). Hai hành động là đi trái hoặc đi phải, phần thưởng chỉ xảy ra khi đến đích. Trong mỗi tập huấn luyện, tác nhân khởi đầu ở một trạng thái ngẫu nhiên và chạy đến khi đến đích. Hành động được chọn theo chiến lược ε-greedy (có xác suất nhỏ khám phá ngẫu nhiên, còn lại chọn hành động tối ưu hiện tại). Sau mỗi bước, bảng Q được cập nhật bằng công thức trên. Sau nhiều tập, giá trị Q ở các trạng thái gần mục tiêu tăng dần, phản ánh rằng các hành động hướng về mục tiêu nhận phần thưởng mong đợi cao hơn\n",
    ".\n",
    "Mô tả chi tiết: Đầu tiên khởi tạo bảng Q có kích thước (số trạng thái) × (số hành động) với giá trị ban đầu 0\n",
    "\n",
    ". Các tham số α (learning rate) và γ (discount) được chọn cố định. Trong vòng lặp huấn luyện, với mỗi tập tác nhân chọn hành động dựa trên ε-greedy (thăm khám hoặc lợi dụng Q hiện tại). Sau khi thực hiện hành động và nhận phần thưởng, Q được cập nhật bằng cách tính sai số temporal difference (dựa trên phần thưởng và giá trị Q lớn nhất tại trạng thái tiếp theo). Quá trình này lặp lại nhiều lần (episodes) để các giá trị Q hội tụ. Kết quả in ra là bảng Q sau khi học, trong đó các giá trị Q ở các trạng thái hướng về đích (ví dụ các bước đi gần đích) được tăng lên nhiều nhất\n",
    ", chứng tỏ tác nhân đã học được lựa chọn hành động tối ưu để đến đích.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
